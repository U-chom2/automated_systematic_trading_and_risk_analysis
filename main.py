"""
æ ªå¼å£²è²·AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ  - ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

å¼·åŒ–å­¦ç¿’ï¼ˆPPOï¼‰+ LSTM/Transformer + ModernBERTã‚’ä½¿ç”¨ã—ãŸ
é«˜åº¦ãªæ ªä¾¡äºˆæ¸¬ãƒ»å£²è²·AIã‚·ã‚¹ãƒ†ãƒ 

æ–¹é‡.mdã«åŸºã¥ã„ãŸå®Ÿè£…ï¼š
- æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡ºï¼ˆLSTM/Transformerï¼‰
- IRãƒ‹ãƒ¥ãƒ¼ã‚¹ç†è§£ï¼ˆModernBERT-jaï¼‰
- å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹æ„æ€æ±ºå®šï¼ˆPPOï¼‰
"""

import sys
import argparse
import asyncio
import logging
from pathlib import Path
from typing import List, Dict, Optional
import torch
import pandas as pd
import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent / "train"))

# åˆ·æ–°ã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from train import Nikkei225TradingPipeline
from models.trading_model import TradingDecisionModel, MarketData
from models.agents.ppo_agent import PPOTradingAgent

logger = logging.getLogger(__name__)


def setup_logging(level: str = "INFO") -> None:
    """ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler("trading_system.log")
        ]
    )


class AITradingSystem:
    """çµ±åˆå‹AIæ ªå¼å£²è²·ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, device: str = None):
        """
        ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        
        Args:
            device: ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ ('mps', 'cuda:0', 'cpu', None for auto-detect)
        """
        # ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•æ¤œå‡º
        if device is None:
            if torch.backends.mps.is_available():
                device = 'mps'  # Apple Silicon GPU
            elif torch.cuda.is_available():
                device = 'cuda:0'  # NVIDIA GPU
            else:
                device = 'cpu'  # CPU fallback
                
        self.device = device
        logger.info(f"AI Trading System initialized on {device}")
        
        # ãƒ¢ãƒ‡ãƒ«æ ¼ç´
        self.model: Optional[TradingDecisionModel] = None
        self.trained_agent: Optional[PPOTradingAgent] = None
    
    def train_model(
        self,
        target_symbols: List[str],
        start_date: str,
        end_date: str,
        total_timesteps: int = 50000,
        initial_cash: float = 10000000,  # 10 million yen
        save_model: bool = True
    ) -> PPOTradingAgent:
        """
        å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        
        Args:
            target_symbols: å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ (ä¾‹: ['7203.T', '6758.T'])
            start_date: è¨“ç·´é–‹å§‹æ—¥ (YYYY-MM-DD)
            end_date: è¨“ç·´çµ‚äº†æ—¥ (YYYY-MM-DD)
            total_timesteps: è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°
            initial_cash: åˆæœŸè³‡é‡‘
            save_model: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ•ãƒ©ã‚°
            
        Returns:
            è¨“ç·´æ¸ˆã¿PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
        """
        logger.info("=" * 60)
        logger.info("å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        logger.info("=" * 60)
        logger.info(f"å¯¾è±¡éŠ˜æŸ„: {target_symbols}")
        logger.info(f"æœŸé–“: {start_date} - {end_date}")
        logger.info(f"è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_timesteps}")
        logger.info(f"åˆæœŸè³‡é‡‘: Â¥{initial_cash:,.0f}")
        logger.info(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        
        # è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ
        pipeline = Nikkei225TradingPipeline(
            target_symbols=target_symbols,
            start_date=start_date,
            end_date=end_date,
            initial_cash=initial_cash,
            commission_rate=0.001,  # 0.1% commission
            window_size=30  # 30æ—¥ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿
        )
        
        # PPOå¼·åŒ–å­¦ç¿’ã§è¨“ç·´
        trained_agent = pipeline.train(
            total_timesteps=total_timesteps,
            learning_rate=3e-4,
            n_steps=1024,
            batch_size=32,
            n_epochs=10,
            device=self.device
        )
        
        self.trained_agent = trained_agent
        
        logger.info("=" * 60)
        logger.info("âœ… å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
        logger.info("=" * 60)
        
        return trained_agent
    
    def load_inference_model(self, model_path: str = None) -> TradingDecisionModel:
        """
        æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        
        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«
        """
        logger.info(f"æ¨è«–ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_path or 'ãƒ‡ãƒ¢ãƒ¢ãƒ‡ãƒ«'}")
        
        # æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = TradingDecisionModel(device=self.device)
        
        # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
        if model_path and Path(model_path).exists():
            model.load(model_path, device=self.device)
            logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {model_path}")
        else:
            logger.info("ğŸ†• æ–°è¦ãƒ‡ãƒ¢ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
        
        model.eval()
        self.model = model
        
        return model
    
    def predict(
        self,
        nikkei_data: np.ndarray,  # [æ—¥æ•°, 3] (high, low, close)
        target_data: np.ndarray,  # [æ—¥æ•°, 3] (high, low, close)  
        ir_news: List[str]
    ) -> Dict[str, float]:
        """
        å£²è²·åˆ¤æ–­å®Ÿè¡Œ
        
        Args:
            nikkei_data: æ—¥çµŒ225ãƒ‡ãƒ¼ã‚¿ (30æ—¥åˆ†)
            target_data: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ (30æ—¥åˆ†)
            ir_news: IRãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ
            
        Returns:
            å£²è²·åˆ¤æ–­çµæœ
        """
        if self.model is None:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚load_inference_model()ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        # MarketDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        market_data = MarketData(
            nikkei_high=nikkei_data[:, 0],
            nikkei_low=nikkei_data[:, 1], 
            nikkei_close=nikkei_data[:, 2],
            target_high=target_data[:, 0],
            target_low=target_data[:, 1],
            target_close=target_data[:, 2],
            ir_news=ir_news
        )
        
        # æ¨è«–å®Ÿè¡Œ
        with torch.no_grad():
            decision = self.model(market_data)
        
        return decision
    
    def demo_mode(self) -> Dict[str, float]:
        """
        ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§æ¨è«–ãƒ†ã‚¹ãƒˆï¼‰
        
        Returns:
            å£²è²·åˆ¤æ–­çµæœ
        """
        logger.info("=" * 60)
        logger.info("ğŸš€ AI Trading System - ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰")
        logger.info("=" * 60)
        
        # ãƒ‡ãƒ¢ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        self.load_inference_model()
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        logger.info("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        np.random.seed(42)
        
        # æ—¥çµŒ225ãƒ‡ãƒ¼ã‚¿ï¼ˆ30æ—¥åˆ†ï¼‰
        nikkei_base = 28000
        nikkei_close = nikkei_base + np.cumsum(np.random.randn(30) * 100)
        nikkei_high = nikkei_close + np.abs(np.random.randn(30) * 50)
        nikkei_low = nikkei_close - np.abs(np.random.randn(30) * 50)
        nikkei_data = np.stack([nikkei_high, nikkei_low, nikkei_close], axis=1)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ ªãƒ‡ãƒ¼ã‚¿ï¼ˆ30æ—¥åˆ†ï¼‰
        target_base = 3000
        target_close = target_base + np.cumsum(np.random.randn(30) * 20)
        target_high = target_close + np.abs(np.random.randn(30) * 10)
        target_low = target_close - np.abs(np.random.randn(30) * 10)
        target_data = np.stack([target_high, target_low, target_close], axis=1)
        
        # IRãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
        ir_news = [
            "2024å¹´ç¬¬3å››åŠæœŸæ±ºç®—ï¼šå£²ä¸Šé«˜ã¯å‰å¹´åŒæœŸæ¯”15%å¢—åã‚’é”æˆ",
            "æ–°è£½å“ã®è²©å£²ãŒè¨ˆç”»ã‚’ä¸Šå›ã‚‹å¥½èª¿ãªæ¨ç§»ã‚’è¦‹ã›ã¦ã„ã¾ã™",
            "é€šæœŸæ¥­ç¸¾äºˆæƒ³ã‚’ä¸Šæ–¹ä¿®æ­£ã€å¢—åå¢—ç›Šã‚’è¦‹è¾¼ã‚€"
        ]
        
        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±è¡¨ç¤º
        logger.info("ğŸ“ˆ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æƒ…å ±:")
        logger.info(f"  æ—¥çµŒ225æœ€æ–°å€¤: {nikkei_close[-1]:.0f} (30æ—¥å¤‰åŒ–ç‡: {(nikkei_close[-1]/nikkei_close[0]-1)*100:.2f}%)")
        logger.info(f"  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ ªæœ€æ–°å€¤: {target_close[-1]:.0f} (30æ—¥å¤‰åŒ–ç‡: {(target_close[-1]/target_close[0]-1)*100:.2f}%)")
        logger.info(f"  IRãƒ‹ãƒ¥ãƒ¼ã‚¹ä»¶æ•°: {len(ir_news)}ä»¶")
        
        # æ¨è«–å®Ÿè¡Œ
        logger.info("ğŸ¤– AIæ¨è«–å®Ÿè¡Œä¸­...")
        decision = self.predict(nikkei_data, target_data, ir_news)
        
        # çµæœè¡¨ç¤º
        self._print_decision_results(decision)
        
        return decision
    
    def _print_decision_results(self, decision: Dict[str, float]) -> None:
        """å£²è²·åˆ¤æ–­çµæœã®è¡¨ç¤º"""
        logger.info("=" * 60)
        logger.info("ğŸ¯ AIå£²è²·åˆ¤æ–­çµæœ")
        logger.info("=" * 60)
        logger.info(f"æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {decision['action']}")
        logger.info(f"ä¿¡é ¼åº¦: {decision['confidence']*100:.1f}%")
        logger.info("")
        logger.info("ğŸ“Š è©³ç´°ç¢ºç‡åˆ†å¸ƒ:")
        logger.info(f"  å¼·å£²ã‚Š:   {decision['sell_prob']*100:5.1f}%")
        logger.info(f"  ãƒ›ãƒ¼ãƒ«ãƒ‰: {decision['hold_prob']*100:5.1f}%")
        logger.info(f"  å°‘é‡è²·ã„: {decision['buy_small_prob']*100:5.1f}%")
        logger.info(f"  å¼·è²·ã„:   {decision['buy_large_prob']*100:5.1f}%")
        logger.info("")
        logger.info(f"ğŸ’° æ¨å¥¨ãƒã‚¸ã‚·ãƒ§ãƒ³: {decision['recommended_position']:.2f}")
        logger.info("   (-0.33=å…¨å£²å´, 0=ãƒ›ãƒ¼ãƒ«ãƒ‰, 1.0=å…¨åŠ›è²·ã„)")
        logger.info("=" * 60)
    
    def evaluate_model(self, model_path: str = None, n_episodes: int = 10) -> Dict[str, float]:
        """
        ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡
        
        Args:
            model_path: è©•ä¾¡å¯¾è±¡ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
            n_episodes: è©•ä¾¡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°
            
        Returns:
            è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        logger.info("=" * 60)
        logger.info("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡")
        logger.info("=" * 60)
        
        if self.trained_agent is None:
            logger.error("è©•ä¾¡å¯¾è±¡ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«è¨“ç·´ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return {}
        
        # è©•ä¾¡å®Ÿè¡Œ
        metrics = self.trained_agent.evaluate(n_episodes=n_episodes)
        
        logger.info("è©•ä¾¡çµæœ:")
        logger.info(f"  å¹³å‡å ±é…¬: {metrics['mean_reward']:.4f}")
        logger.info(f"  å ±é…¬æ¨™æº–åå·®: {metrics['std_reward']:.4f}")
        logger.info(f"  å¹³å‡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é•·: {metrics['mean_length']:.1f}")
        logger.info(f"  æœ€å°å ±é…¬: {metrics['min_reward']:.4f}")
        logger.info(f"  æœ€å¤§å ±é…¬: {metrics['max_reward']:.4f}")
        
        return metrics


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(
        description="æ ªå¼å£²è²·AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¼·åŒ–å­¦ç¿’+LSTM/Transformer+ModernBERTï¼‰"
    )
    
    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    parser.add_argument(
        '--mode', 
        choices=['train', 'inference', 'demo', 'evaluate'],
        default='demo',
        help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰'
    )
    
    # è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--symbols', nargs='+', default=['7203.T', '6758.T', '9984.T'],
                       help='å¯¾è±¡éŠ˜æŸ„ï¼ˆä¾‹: 7203.T 6758.Tï¼‰')
    parser.add_argument('--start-date', default='2022-01-01', help='é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--end-date', default='2024-01-01', help='çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--timesteps', type=int, default=50000, help='è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°')
    parser.add_argument('--initial-cash', type=float, default=10000000, help='åˆæœŸè³‡é‡‘')
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--device', choices=['mps', 'cuda', 'cuda:0', 'cpu'],
                       help='ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ï¼ˆè‡ªå‹•æ¤œå‡º: æŒ‡å®šãªã—ï¼‰')
    parser.add_argument('--model-path', help='ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--log-level', default='INFO', help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«')
    
    # è©•ä¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--eval-episodes', type=int, default=10, help='è©•ä¾¡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    setup_logging(args.log_level)
    
    try:
        # AIã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        ai_system = AITradingSystem(device=args.device)
        
        if args.mode == 'train':
            # è¨“ç·´ãƒ¢ãƒ¼ãƒ‰
            logger.info("ğŸ“ è¨“ç·´ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
            ai_system.train_model(
                target_symbols=args.symbols,
                start_date=args.start_date,
                end_date=args.end_date,
                total_timesteps=args.timesteps,
                initial_cash=args.initial_cash
            )
            
            # è¨“ç·´å¾Œè©•ä¾¡
            if ai_system.trained_agent:
                ai_system.evaluate_model(n_episodes=args.eval_episodes)
                
        elif args.mode == 'inference':
            # æ¨è«–ãƒ¢ãƒ¼ãƒ‰
            logger.info("ğŸ”® æ¨è«–ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
            model = ai_system.load_inference_model(args.model_path)
            
            # TODO: å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã¨æ¨è«–å®Ÿè¡Œ
            logger.info("å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®æ¨è«–ã¯ä»Šå¾Œå®Ÿè£…äºˆå®š")
            logger.info("ç¾åœ¨ã¯ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã‚’ãŠè©¦ã—ãã ã•ã„: --mode demo")
            
        elif args.mode == 'demo':
            # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰
            decision = ai_system.demo_mode()
            
        elif args.mode == 'evaluate':
            # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
            logger.info("ğŸ“Š è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰")
            if args.model_path:
                # TODO: ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
                logger.info("ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¯ä»Šå¾Œå®Ÿè£…äºˆå®š")
            else:
                logger.error("è©•ä¾¡ã«ã¯ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ãŒå¿…è¦ã§ã™: --model-path")
                
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­æ–­ï¼‰")
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    finally:
        logger.info("ğŸ AI Trading System åœæ­¢")


if __name__ == "__main__":
    main()